{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "sys.path.append('./src')\n",
    "import helpers\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ’ŽðŸ˜Ž\n",
    "def p(v, fn=None, **kwargs):\n",
    "  print(v)\n",
    "  fn = lambda k, v: display([k, v]) if fn is None else fn\n",
    "  [print(f\"{k}: {v}\") for k, v in kwargs.items()]\n",
    "  return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "governor_urls = [f'https://www.maine.gov/sos/cec/elec/results/2018/govd-{x}.xlsx' for x in [1, 2, 3, 4, 5]]\n",
    "congress_urls = [f'https://www.maine.gov/sos/cec/elec/results/2018/congressd2-{x}.xlsx' for x in [1, 2, 3, 4]]\n",
    "\n",
    "raw_governor_datasets = [pd.read_excel(helpers.cached_file(url=f), index_col=0) for f in governor_urls]\n",
    "raw_congress_datasets = [pd.read_excel(helpers.cached_file(url=f), index_col=0) for f in congress_urls]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What possible votes are we working with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display([len(df) for df in raw_governor_datasets])\n",
    "display([len(df) for df in raw_congress_datasets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcols = raw_governor_datasets[0].columns.tolist()\n",
    "display(gcols)\n",
    "raw_governor_datasets[0].groupby(gcols[3])[gcols[0]].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccols = raw_congress_datasets[0].columns.tolist()\n",
    "display(ccols)\n",
    "raw_congress_datasets[0].groupby(ccols[3])[ccols[0]].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Votes\n",
    "Remove the (1234) numbers at the end of candidates so they match across votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "governor_datasets = [df.replace(r' \\([0-9]{4}\\)', '', regex=True)\n",
    "                    for df in raw_governor_datasets]\n",
    "congress_datasets = [df.replace(r' \\([0-9]{4}\\)', '', regex=True)\n",
    "                    for df in raw_congress_datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scanning the ballots for possible Write-in errors\n",
    "\n",
    "When tallying 2018 election results write-ins were treated as undervotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writein_errors(df):\n",
    "    CHOICES = df.columns[3:].tolist()\n",
    "\n",
    "    undervotes = [df[c] == 'undervote' for c in CHOICES]\n",
    "    writeins = [df[c] == 'Write-in' for c in CHOICES]\n",
    "    display(undervotes[0])\n",
    "    \n",
    "    writein_writeins = [writeins[i] & writeins[i+1] & ~undervotes[i+2] for i in range(len(CHOICES) - 2)]\n",
    "    writein_undervotes = [writeins[i] & undervotes[i+1] & ~undervotes[i+2] for i in range(len(CHOICES) - 2)]\n",
    "    undervote_writeins = [undervotes[i] & writeins[i+1] & ~undervotes[i+2] for i in range(len(CHOICES) - 2)]\n",
    "    \n",
    "    any_writein_writein = any(writein_writeins)\n",
    "    any_writein_undervote = any(writein_undervotes)\n",
    "    any_undervote_writein = any(undervote_writeins)\n",
    "    all_errors = or_indexers([any_writein_writein, any_writein_undervote, any_undervote_writein])\n",
    "    return all_errors\n",
    "\n",
    "def writein_errors2(df):\n",
    "    CHOICES = df.columns[3:].tolist()\n",
    "\n",
    "    undervotes = pd.concat([df[c] == 'undervote' for c in CHOICES], axis=1, keys=CHOICES)\n",
    "    writeins = pd.concat([df[c] == 'Write-in' for c in CHOICES], axis=1, keys=CHOICES)\n",
    "\n",
    "    \n",
    "    choice_triple = [cs for cs in zip(CHOICES, CHOICES[1:], CHOICES[2:])]\n",
    "    \n",
    "    writein_writeins = pd.concat([writeins[c1] & writeins[c2] & ~undervotes[c3]\n",
    "                                  for c1, c2, c3 in choice_triple], axis=1, keys=CHOICES)\n",
    "    writein_undervotes = pd.concat([writeins[c1] & undervotes[c2] & ~undervotes[c3]\n",
    "                                    for c1, c2, c3 in choice_triple], axis=1, keys=CHOICES)\n",
    "    undervote_writeins = pd.concat([undervotes[c1] & writeins[c2] & ~undervotes[c3]\n",
    "                                    for c1, c2, c3 in choice_triple], axis=1)\n",
    "    df = pd.DataFrame()\n",
    "    df['any_writein_writein'] = writein_writeins.any(axis=1)\n",
    "    df['any_writein_undervote'] = writein_undervotes.any(axis=1)\n",
    "    df['any_undervote_writein'] = undervote_writeins.any(axis=1)\n",
    "#     all_errors = or_indexers([any_writein_writein, any_writein_undervote, any_undervote_writein])\n",
    "    return df.any(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('./output/write-in-errors.xlsx') as writer:\n",
    "    for i, df in enumerate(governor_datasets):\n",
    "        df[writein_errors2(df)].to_excel(writer, sheet_name=f'Governor ({i+1})')\n",
    "    for i, df in enumerate(congress_datasets):\n",
    "        df[writein_errors2(df)].to_excel(writer, sheet_name=f'Rep to Congress - D2 ({i+1})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(df):\n",
    "    CHOICES = df.columns[2:].tolist()\n",
    "    ID = df.index.name\n",
    "    \n",
    "    vote_counts = df[CHOICES].apply(pd.value_counts).fillna(0).astype(int)\n",
    "    melted_choices = df.reset_index().melt(id_vars=[ID], value_vars=CHOICES)\n",
    "    combined_vote_counts = melted_choices.drop_duplicates([ID, 'value'])['value'].value_counts().rename(\"total\")\n",
    "    \n",
    "    return combined_vote_counts.to_frame().join(vote_counts)\n",
    "\n",
    "def write_combined_summaries(writer, prefix, datasets):\n",
    "    agg = summarize(governor_datasets[0])\n",
    "    for df in governor_datasets[1:]:\n",
    "        summary = summarize(df)\n",
    "        summary.columns = agg.columns\n",
    "        agg += summary.reindex(agg.index, fill_value=0)\n",
    "    for i, df in enumerate(governor_datasets):\n",
    "        summary = summarize(df)\n",
    "        summary.to_excel(writer, sheet_name=f'Governor ({i+1})')\n",
    "\n",
    "with pd.ExcelWriter('./output/raw-vote-summaries.xlsx') as writer:\n",
    "    for i, df in enumerate(congress_datasets):\n",
    "        summary = summarize(df)\n",
    "        summary.to_excel(writer, sheet_name=f'Rep to Congress - D2 ({i+1})')\n",
    "        display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = summarize(governor_datasets[0])\n",
    "for df in governor_datasets[1:]:\n",
    "    summary = summarize(df)\n",
    "    summary.columns = agg.columns\n",
    "    agg += summary.reindex(agg.index, fill_value=0)\n",
    "agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
